{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 12: XPath part 1\n",
    "\n",
    "Over this week and next week we'll be going over XPath, but also discovering more about how to parse over multiple files and do more advanced stuff with lists and nested accumulator patterns.\n",
    "\n",
    "## Readings for this week\n",
    "\n",
    "For new to XML, please start here: https://www.w3schools.com/xml/default.asp.  Read Introduction through Attributes, then stop.  Those who've worked with XML should at least take a skim through those pages and refresh your understanding of the XML lingo.\n",
    "\n",
    "## What is XML?\n",
    "\n",
    "If you truly have zero knowledge of XML, I invite you to start with the a good skim of the [Wikipedia page](https://en.wikipedia.org/wiki/XML) on the subject. Don't pour over it, but it'll provide some important background vocabulary and context.  Anyhow, XML is ruleset for marking up documents in specific ways, and has been extended to a method of storing data in a very structured way.  Instead of having a row/column structure like a CSV file, you can have nested and thus much more complex data storage this way.\n",
    "\n",
    "Much of library metadata is stored in XML marked up documents, and that's the focus of the Metadata in Theory and Practice class offered at the iSchool.  Meanwhile, HTML is another markup language that works very similarly to XML.  Unless the HTML is severely malformed, techniques to extract data out of XML will also be useful for extracting data out of web pages.\n",
    "\n",
    "## What is XPath?\n",
    "\n",
    "XPath (https://en.wikipedia.org/wiki/XPath) is a query language (a la SQL, kind of) used to describe both locations for items and data extraction for XML documents/data.  This means that you can use it to both locate a specific element within an XML document but it also includes functions to pull out desired values.  Much of the time that's the text of that element, but sometimes you'll want other stuff.\n",
    "\n",
    "XPath is a system that is platform and tool independent, and thus you can actually find tools for it in the Oxygen XML editor, and there are a few other resources.  There are many Python tools that utilize XPath and have functions for applying XPath queries, but we're going to explore one of those.  \n",
    "\n",
    "## Installing lxml\n",
    "\n",
    "For this first week we'll be using some other tools than python for exploring xpath, but it wouldn't hurt to go ahead and get this installed.\n",
    "\n",
    "Your anaconda installation should already have included an installation of lxml.  Should you need it, lxml is a module available from PyPi, which means you can use pip to install it.  Please follow these directions:\n",
    "\n",
    "1. Open up your terminal or command prompt (this is the same as you did when you were testing your anaconda installation at the beginning of the semester.\n",
    "2. Type in `pip install lxml` and press enter.  You should not get an error.\n",
    "3. It should begin a downloading process and not end in a \"failed\" statement.\n",
    "4. Once you're back to the normal command prompt, go into PyCharm and open up your Python Console.\n",
    "5. Type in `from lxml import etree` and press enter.  You should not see anything returned.  Let me know if you get an error an what that error is.\n",
    "    \n",
    "    \n",
    "# Xpath tools\n",
    "\n",
    "There are several tools that will run xpath queries.  Oxygen will work on valid xml files, although it tends to complain pretty hard about most common HTML because the internet is the wild west for validity.\n",
    "\n",
    "There are other tools, like XPath Helper in chrome that can work.\n",
    "\n",
    "Also, google sheets has a function called `IMPORTXML(url, xpath)` that will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essential vocabulary\n",
    "\n",
    "No matter which scraping or parsing tool that you use, you will not be able to navigate the documentation or create new things if you don't know the language behind the purpose.\n",
    "\n",
    "Let's take this one example:\n",
    "\n",
    "```XML\n",
    "<a href = \"http://ischool.illinois.edu/\">iSchool</a>\n",
    "```\n",
    "\n",
    "This is how you make a hyperlink in HTML.  The bit between the two tags is what shows up on the website and the bit in quotes after the href is where the link will go when you click it.  \n",
    "\n",
    "HTML can be considered to be a specific form of XML.  Remember that XML is just a set of rules, and HTML is just one of those sets (I think there are purists who would disagree on a few points, because modern web browsers allow you to violate every known rule of XML and still render, but that's not a debate to have here).\n",
    "\n",
    "Here are the essential names that you need to know:\n",
    "\n",
    "\n",
    "* element name:  this is `a`, where you see in the <>.  The element contains all the information that you want.  The <> define where certain parts of the element exist.  Don't worry, we'll get into more of that.\n",
    "* node:  roughly, this is the entire contraption that you see there.  The a element and everything about it and what's in it.\n",
    "* opening tag: this is the `<a>` piece\n",
    "* closing tag:  this is the `</a>` piece\n",
    "* element content or value:  sometimes elements will hold just text, another element, a mix of both, or nothing at all!  The stuff that is between the > and < (so after the opening tag and before the closing tag), is the element's content.\n",
    "* attributes:  these are key/value pairs that appear inside the opening tag.  You can see this is the href.  \n",
    "* attribute name:  the thing on the left side of the =.  Much like dictionaries, all attribute names must be unique inside the opening tag.\n",
    "* attribute value:  the thing on the right side of the =.  This is the URL.  Generally you'll find these in quotes, but not always.\n",
    "\n",
    "Meanwhile, all valid XML must have a single root element that everything belongs inside.  You can see this in proper HTML, which is the `<html>` tag.  Every other element that you see in this website is a descendant element of that root.  Elements (except for the root element) have a parent element.\n",
    "\n",
    "```XML\n",
    "\n",
    "<root>\n",
    "    <middle>\n",
    "        <child>stuff</child>\n",
    "    </middle>\n",
    "</root>\n",
    "```\n",
    "\n",
    "Parent, child, and tree:\n",
    "\n",
    "`root` is the parent of `middle`, and `middle` is the parent of `child`.  Together these make the tree.  \n",
    "\n",
    "When you are constructing XPath queries, you'll need to operationalize the patterns and locations that you see into these sorts of terms.  Once you can do that, you can string together the names of things in the XML tree and XPath punctuation to build up your query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XPath punctuation and syntax\n",
    "\n",
    "The simplest XPath query is a list of elements, separated by `/`, to describe an exact location in the tree.  For example, in the previous structure, I could access the location of `child` via:\n",
    "\n",
    "`/root/middle/child`\n",
    "\n",
    "This should look very similar to a URL or a file path.  The `/` is used in a similar way.\n",
    "\n",
    "However, sometimes there are multiple elements that you want or you don't need to specify the full path to that element.  You can use `//` to have the query search at any level of the tree instead of starting at the root.\n",
    "\n",
    "`//child`\n",
    "\n",
    "This query would look for the `child` tag at any level in the tree.\n",
    "\n",
    "## Describing stuff \n",
    "\n",
    "* an element name needs no other syntax to be to be a reference for an element, as you can see with our references with `child`\n",
    "* `/` look only 1 level deep, so only for immediate children of the element proceeding it\n",
    "* `//` look anywhere in the descendants of the element proceeding it\n",
    "* `.` indicate the current node (you'll usually use this inside of functions)\n",
    "* `..` indicate the parent node of the current element.  You can use this to have it `look` up to a previous element.  For example, \"find this specific element, but then select the element parent to it\"\n",
    "* `@` this is used before a name to indicate that you are talking about an attribute name instead of an element name.  For example, `@href` for an `a` element.  \n",
    "* `element[position number]`:  index starting at 1, allows you to indicate the \"nth\" instant of that element.  Example, `a[3]` would be the third a found with that query.\n",
    "* `element[logical check]` You can place a variety of functions and other boolean checks inside the `[]`.  There are multiple things you can put in here (https://www.w3schools.com/xml/xsl_functions.asp).\n",
    "* `element[@attribute = 'something']` you can use this to select an element with an attribute that has a specific value.  You cas alse reference the current node's element values with `.`, so `//p[. = \"thing\"]` finds all the p elements that have the element text value of exactly \"thing\".  Warning! This will look deeper into the children of that node.  If you want to look at the text value of the current element, you should use `text()` instead of `.`.  So `element[text() = \"thing\"]`.  You can use `text()` or `.` in any of the logical checks that you want.\n",
    "* You can use compound boolean checks inside the [], such as `//element[@attribute = \"something\" and contains(., \"another\")]` . Connect these boolean checks with `and` or `or`.\n",
    "* `*` is a wildcard used to represent \"any element\". So, you could say `//*[@class = \"title\"]` to find any element that has a class atribute value of \"title\".\n",
    "\n",
    "Of course, all these things are used to just select the element in question.  From there, you have te extract out what you want.  This is a bit opaque when using a pretty normal xpath tool, but made much more explicit when dealing with things in python.  Particularly with lxml.  You'll only get an element object if you don't select the content that you want.  \n",
    "\n",
    "## Extracting stuff \n",
    "\n",
    "* the attribute value\n",
    "    * you can get this by adding `@attribute` to the end of a query\n",
    "    * example:  `//a/@href`\n",
    "* the element content\n",
    "    * you have to use a spific function at the end of the query to get the text: `text()`  Note the `()` in there, that are required.\n",
    "    * Example:  `//a/text()`\n",
    "    * Remember that `/` will only look for text that belongs to the element that you have selected.  Some tools are mare permissive about this, but things like lxml are not.  If there are additional elements in there, such as text in a `<b>` tag, it will grab all the text around that tag, but none of the contents.  \n",
    "    * For example, in `<p>Hello <b>world</b> humans.</p>`, if you use `//p/text()` you'll only get back \"Hello . humans.\".\n",
    "    * You can ask it to grab all text at any descendant level under the element that you have selected.  You already know the `//` notation, and you can add it to `text()` to achieve this effect.  So `//p//text()` would grab all the text in there. \n",
    "\n",
    "We'll use all of these in our example below, but it can be helpful to copy these and keep them handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 steps to writing a query\n",
    "\n",
    "This is a very iterative process, but it can be helpful to have at least some place to start.  \n",
    "\n",
    "## 1:  Identify your target\n",
    "\n",
    "You'll either be dealing with an XML file here or you'll want to view source on the website that you're after.  Some websites have protections put in place to prevent you accessing the content, so there may be oddities.  \n",
    "\n",
    "For websites, copy one of the things you are after and go into the page source.  Search inside the page code to find where it is.  Chrome developer tools (View>Developer>Developer Tools) allows you to navigate the structure in an easier way.\n",
    "\n",
    "Take note of where that content is, what the element is, parent element is, any attributes it has, those attribute values, etc.  These are all clues that you can use to help select the proper content.  Remember that you arent just after the content that you want, you are after the element itself and the things around it.\n",
    "\n",
    "In our case, this content is inside an `a` element that is in a `td` (table data) element in an HTML table.\n",
    "\n",
    "Goal:  be able to operationalize in formal XML vocabulary where the content is located.\n",
    "\n",
    "## 2:  Pick your starting place\n",
    "\n",
    "Often, the first element that you start looking for will determine the approach that you end up having to take.  \n",
    "\n",
    "You have to find a balance that:\n",
    "\n",
    "* selects all the things that you want\n",
    "* not so much other stuff that you have too much noise to clean up\n",
    "\n",
    "There is where you must know the structure of what you are dealing with, and where to find this balance. Something broad enough that it gets you started, but not something so broad that it brings in too much or doesn't provide value.  This is sort of where the art form comes in, and an experienced eye can help direct you.\n",
    "\n",
    "Goal:  get as close as possible to your target content without losing any of it in the process.\n",
    "\n",
    "## 3:  Start drilling down\n",
    "\n",
    "Once you have the starting place, you will start adding elements and other selectors after it until all that is left are the things that you want.  You'll drill in closer and closer, being careful to not leave anything that you want behind.\n",
    "\n",
    "There may be situations where you start down a perfectly reasonable path, but with that path there may be no way to uniquely specify what you are after.  This may mean that you need to back up and start from a different place, or sometimes you need to bring the values in to Python proper and use string methods etc to get out what you want.\n",
    "\n",
    "## 4:  Extract the content that you want out of the node\n",
    "\n",
    "Your first job is to select the node that has what you want, and then you add some content extraction functions or other selectors to your query.  In the best of worlds this will produce exactly the content that you want and nothing else.  However, you may not be so lucky with the structure that you are given, and you might need to do some further processing (like in python) to further filter out what you want.\n",
    "\n",
    "## 5:  Check your work\n",
    "\n",
    "You may have set along several paths to get your answer, and don't worry, there isn't some mythical place that you must discover.  You are done with the first query you find that holds true across all your cases.  Let's look at these two pieces:\n",
    "\n",
    "1. \"first one\" there's no value in chasing down every path to try and find some perfect solution.  Don't overengineer the details of what you are after if those details don't add anything to what you are trying to get at.\n",
    "2. \"holds true across all your cases\" You may have found a solution to one of your cases, and so you need to test that solution onto all of your data.  This doesn't imply that you have the capability of doing just that (applying an algorithm on many files or whatever you have) and checking that what you are getting back is what you are after.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worked example\n",
    "\n",
    "Let's take this website:  http://www.j-archive.com/showplayer.php?player_id=11699  This is for a player on Jeopardy who participated in two games.  Our goal is to get the text out about the two games.  Yes, there are only two here in this case, but think bigger.  What if you wanted the data for Ken Jennings, http://j-archive.com/showplayer.php?player_id=1, or wanted it to run over all 11,000 players?\n",
    "\n",
    "This website is PHP, meaning that the data content reported out has a steady structure.\n",
    "\n",
    "## Step 1:  where do we want to start?\n",
    "\n",
    "Well, we know that what we want is within an `a` element. So we can start by just looking for that.\n",
    "\n",
    "`//a`\n",
    "\n",
    "This gives us 12 results, which includes what we want, but a few extra things like the player stats and some of the links in the footer.\n",
    "\n",
    "## Step 2:  Drill down\n",
    "\n",
    "From an element perspective, we've gone as far down as we can get.  At this point we have a choice: \n",
    "\n",
    "1.  Add in a conditional that can uniquely identify the `a` elements that we want from the ones we don't.\n",
    "2.  Back up and try a different starting point.\n",
    "\n",
    "We can use both of these to successfully drill down.\n",
    "\n",
    "### Filtering the `a` elements with the `starts-with()` function\n",
    "\n",
    "Looking at the results, we can tell a few differences in the `a` elements that we want versus the ones that we don't.\n",
    "\n",
    "Here are the element values for all the `a` elements:\n",
    "\n",
    "```\n",
    "[current season]\n",
    "[last season]\n",
    "[all seasons]\n",
    "[prizes]\n",
    "[wagering calculator]\n",
    "[help]\n",
    "#7614, aired 2017-10-19\n",
    "#7613, aired 2017-10-18\n",
    "[player statistics]\n",
    "Jeopardy!\n",
    "JBoard.tv\n",
    "```\n",
    "\n",
    "The ones that we want have dates, but also all start with the `#` character.  We can use the `starts-with()` xpath function to filter these out.\n",
    "\n",
    "Here's the syntax:  `starts-with(node, text)`\n",
    "\n",
    "That node trick is a weird one.  There are other things you can do, but for the most part you are going to provide one of two things:\n",
    "\n",
    "1. `starts-with(., \"stuff\")` to check the current node\n",
    "2. `starts-with(@attribute, \"stuff\")` to check that attributes value\n",
    "\n",
    "Each of these things are in relation to the element that you call the function into. The function call goes into the `[]` after the element in your selector.  Again, all this is easier to see with an example.\n",
    "\n",
    "So we know that we're looking for \"#\" at the start text value, and that it's for the element text itself.  This means that we want:\n",
    "\n",
    "* to call the function on the `a` tag, so:  `a[starts-with(...)]`\n",
    "* to reference the current node (the text of the `a` element itself), so:  `.` (this shouldn't be in quotes because it is a literal part of the syntax).\n",
    "* and look for #, so: `\"#\"`\n",
    "\n",
    "Putting all that together, we can use:\n",
    "\n",
    "`//a[starts-with(., \"#\")]`\n",
    "\n",
    "### Filtering the a with the `contains()` function\n",
    "\n",
    "We could have also checked the contents of the URL. Looking closely, we can see that they have a URL with \"game_id\" in it.  The `contains()` function works similarly to `starts-with()`.  You call it on the element you want to test, then provide it the thing to look at, and what the content is.\n",
    "\n",
    "* we want to call it on our `a` element, so:  `a[contains(...)]`\n",
    "* we want it to look in the `href` content, so:  `@href` (again, no quotes here)\n",
    "* we want it to look for \"game_id\", so `\"game_id\"`\n",
    "\n",
    "Putting this all together, we get:\n",
    "\n",
    "`//a[contains(@href, \"game_id\")]`\n",
    "\n",
    "### Step 3:  testing it on more examples\n",
    "\n",
    "Great!  Now, this works for our small example. But this website isn't exactly as steady as it seems.  We can try this on the Ken Jennings site.  Ahh, there are links with this same format all over the place in the free text.  So this is being explicit about what it's looking for, but not specific about the location.  \n",
    "\n",
    "This is the time to back up.\n",
    "\n",
    "### aaaaand Backing up and adding more location information\n",
    "\n",
    "We know that the `a` elements we want are in a `td` element.  We can try adding that in.\n",
    "\n",
    "`//td/a[starts-with(., \"#\")]`\n",
    "\n",
    "This still works on our smaller example, let's try it on Ken.\n",
    "\n",
    "And that's done it!  We've added just enough location detail to uniquely separate out what we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting from the other end\n",
    "\n",
    "In the previous example, we started at the shallowest levels possible.  We started right at the `a` and had to break into testing the content to differentiate.  However, we could have started from an element further away from the content and drilled down more structurally.  Had we done this, we could have avoided the function entirely.\n",
    "\n",
    "We know that the things we want are in a table.  So let's look for the tables.\n",
    "\n",
    "`//table`\n",
    "\n",
    "This gives us 2 tables.  One has some other stuff, one has the stuff that we want.  We can put a position number in the brackets to select one that we want.\n",
    "\n",
    "`//table[2]`\n",
    "\n",
    "This gives us the game table. Now we can drill into the table structure.  This requires a bit of the HTML know how, but you can also just look in the structure and copy what you see.\n",
    "\n",
    "We know what we want is in a td:\n",
    "\n",
    "`//table[2]/tbody/tr/td`\n",
    "\n",
    "This is giving us all the td cells.  The data that we want is in the first td of teach tr.  So we could use a position call on the td to say that we want the first one.\n",
    "\n",
    "`//table[2]/tbody/tr/td[1]`\n",
    "\n",
    "So it looks like we've gotten what we want, and we've got the node.  This would be what we would need to do if the content we want wasn't in an `a` element.  Because it is, we can say \"the a element in the tds\".\n",
    "\n",
    "`//table[2]/tbody/tr/td/a`\n",
    "\n",
    "## exploiting a CSS artifact\n",
    "\n",
    "Sometimes the CSS of a website can give a lot away allow you to be much more specific than you might originally have thought of.  Unfortunately, this kind of CSS exploit usually doesn't reveal itself to you unless you are digging through the row HTML.  Some websites are structured such that many of the elements have class name or other style values that you can exploit.  \n",
    "\n",
    "The cool thing is that all the CSS codes added in are added as attribute values, and we know how to look those up with XPath.  \n",
    "\n",
    "Taking another look at the `a` element, there's nothing juicy happening there. However, looking up one level at the tds that have our game info, we can see that they have `style = \"width:140px\"`.  This sets the cell to a fixed width, but also gives us something that we can look up.  You can do a search within the source text for 140px and see that it only appears in the tds that have the data we want.  So we can select those explicitly.\n",
    "\n",
    "`//td[@style = \"width:140px\"]/a`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we've got what we've come for\n",
    "\n",
    "Let's not forget that so far we've only selected the node that we want.  None of the queries that we've run would have given us the text content that we wanted.\n",
    "\n",
    "## Grabbing the text\n",
    "\n",
    "To get the element text out of the element, we can add `text()` to the end our selection statement. \n",
    "\n",
    "In the GUI tools that we are using this may not seem to make much of a difference, but if you were to run this in python you would get the actual text back.\n",
    "\n",
    "## Grabbing the URL\n",
    "\n",
    "Say that you wanted to get all the ULSs for each of these links.  Perhaps you are writing a scraper of some sort that wants to harvest all the game links for a certain subset of players.  Etc.  This will feel strange after having to do text(), but to get the attribute text out you add `@attributename` to the end of the query.\n",
    "\n",
    "`//td/a/@href`\n",
    "\n",
    "## Remember the strategy that we took\n",
    "\n",
    "We built up the query first to uniquely select the node that had the information that we wanted.  Once we had a query that only selected what we want, we can add an extraction phrase to it.  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
